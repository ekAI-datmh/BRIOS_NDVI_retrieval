import os
import json
import argparse
from datetime import datetime
from collections import defaultdict
from loguru import logger

"""
Processes date mapping JSON files to create a one-to-one mapping
by finding the nearest original date for each composite date.

This script walks through a directory, finds JSON files generated by
ndvi_retrieval.py and rvi_retrieval.py, and for each file, it generates
a new JSON file with a `_nearest` suffix. The new file contains a
one-to-one mapping from a composite date to the single closest
original satellite image date.
"""

def find_nearest_date(target_date_str: str, date_list_str: list[str]) -> str:
    """Finds the date in a list that is closest to the target date.

    Args:
        target_date_str: The target date as a 'YYYY-MM-DD' string.
        date_list_str: A list of dates as 'YYYY-MM-DD' strings.

    Returns:
        The date string from the list that is closest to the target date.
    """
    target_date = datetime.strptime(target_date_str, '%Y-%m-%d')
    closest_date_str = min(
        date_list_str,
        key=lambda d: abs(datetime.strptime(d, '%Y-%m-%d') - target_date)
    )
    return closest_date_str

def process_date_mapping_file(
    json_file_path: str, input_folder: str, output_folder: str
) -> None:
    """
    Reads a date mapping JSON, finds the nearest original date for each
    composite date, and saves a new one-to-one mapping to the output folder.

    The original mapping is many-to-one (many original dates to one composite date).
    This function creates a one-to-one mapping by selecting the original date
    that is closest in time to its composite date. The output file is saved
    in a corresponding path inside the output_folder.

    Args:
        json_file_path: The path to the input JSON file.
        input_folder: The root directory of the input files.
        output_folder: The root directory where output files will be saved.
    """
    logger.info(f"Processing {json_file_path}...")
    try:
        with open(json_file_path, 'r') as f:
            original_mapping = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError) as e:
        logger.error(f"  Could not read or parse {json_file_path}: {e}")
        return

    inverted_mapping = defaultdict(list)
    for orig_date, comp_date in original_mapping.items():
        inverted_mapping[comp_date].append(orig_date)

    new_mapping = {}
    for comp_date, orig_dates in inverted_mapping.items():
        if not orig_dates:
            continue
        new_mapping[comp_date] = find_nearest_date(comp_date, orig_dates)
    
    sorted_new_mapping = dict(sorted(new_mapping.items()))

    # Determine output path, preserving the directory structure
    relative_path = os.path.relpath(json_file_path, input_folder)
    new_base_path = os.path.join(output_folder, relative_path)
    
    path_without_ext, ext = os.path.splitext(new_base_path)
    new_file_path = f"{path_without_ext}_nearest{ext}"

    try:
        # Ensure the output directory exists
        os.makedirs(os.path.dirname(new_file_path), exist_ok=True)
        with open(new_file_path, 'w') as f:
            json.dump(sorted_new_mapping, f, indent=4)
        logger.success(f"  Successfully created nearest mapping: {new_file_path}")
    except IOError as e:
        logger.error(f"  Could not write to {new_file_path}: {e}")

def main(input_folder: str, output_folder: str) -> None:
    """
    Walks through the input_folder, finds date mapping JSONs for NDVI and RVI,
    processes them to find the nearest date matches, and saves them to the
    output_folder, preserving the directory structure.

    Args:
        input_folder: Path to the main folder with ROI sub-folders.
        output_folder: Path to the destination folder for the new JSON files.
    """
    logger.info(f"Starting to search for date mapping files in '{input_folder}'...")
    logger.info(f"Output will be saved in '{output_folder}'.")
    found_files = 0
    for root, _, files in os.walk(input_folder):
        for filename in files:
            # Avoid processing already processed files
            if filename.endswith("_nearest.json"):
                continue

            if ('ndvi' in filename or 'rvi' in filename) and filename.endswith('_date_mapping.json'):
                json_path = os.path.join(root, filename)
                process_date_mapping_file(json_path, input_folder, output_folder)
                found_files += 1

    if found_files == 0:
        logger.warning("No matching date mapping files found to process.")
    else:
        logger.info(f"Finished processing. Found and processed {found_files} files.")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Process date mapping JSON files to find the nearest date matches."
    )
    parser.add_argument(
        "input_folder", 
        help="The path to the main folder containing ROI sub-folders with date mapping JSONs."
    )
    parser.add_argument(
        "output_folder",
        help="The path to the destination folder where new JSON files will be saved, preserving the structure."
    )
    args = parser.parse_args()
    main(args.input_folder, args.output_folder) 